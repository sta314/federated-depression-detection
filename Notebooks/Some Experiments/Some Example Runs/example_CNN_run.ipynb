{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress = True)\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df = pd.read_csv(\"daicwoz/train_split.csv\").fillna(0).replace('[^0-9]', '', regex=True).rename(columns={\"PHQ8_Binary\": \"PHQ_Binary\", \"PHQ8_Score\": \"PHQ_Score\"})\n",
    "test_labels_df = pd.read_csv(\"daicwoz/test_split.csv\").fillna(0).replace('[^0-9]', '', regex=True)\n",
    "val_labels_df = pd.read_csv(\"daicwoz/dev_split.csv\").fillna(0).replace('[^0-9]', '', regex=True).rename(columns={\"PHQ8_Binary\": \"PHQ_Binary\", \"PHQ8_Score\": \"PHQ_Score\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_files(data_dir, sr=16000):\n",
    "    file_ids = os.listdir(data_dir)\n",
    "    file_paths = []\n",
    "    types = []\n",
    "    labels = []\n",
    "    labels_binary = []\n",
    "\n",
    "    for file_id in file_ids:\n",
    "        file_path = os.path.join(data_dir, file_id, file_id + \"_AUDIO.wav\")\n",
    "            \n",
    "        if int(file_id) in train_labels_df[\"Participant_ID\"].values:\n",
    "            types.append(0)\n",
    "            labels.append(train_labels_df[train_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Score'].values[0])\n",
    "            labels_binary.append(train_labels_df[train_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Binary'].values[0])\n",
    "            \n",
    "        elif int(file_id) in test_labels_df[\"Participant_ID\"].values:\n",
    "            types.append(1)\n",
    "            labels.append(test_labels_df[test_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Score'].values[0])\n",
    "            labels_binary.append(test_labels_df[test_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Binary'].values[0])\n",
    "        else:\n",
    "            types.append(2)\n",
    "            labels.append(val_labels_df[val_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Score'].values[0])\n",
    "            labels_binary.append(val_labels_df[val_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Binary'].values[0])\n",
    "        file_paths.append(file_path)\n",
    "\n",
    "    return file_ids, file_paths, types, labels, labels_binary\n",
    "\n",
    "data_dir = \"edaicwoz/wav\"\n",
    "\n",
    "file_ids, file_paths, types, labels, labels_binary = load_audio_files(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] preparing data...\n"
     ]
    }
   ],
   "source": [
    "sr = 16000\n",
    "chunk_secs = 15\n",
    "chunk_floats = sr * chunk_secs\n",
    "\n",
    "\n",
    "def prepare_audio_set(file_paths):\n",
    "\n",
    "    samples = []\n",
    "    samples_types = []\n",
    "    samples_labels = []\n",
    "    samples_labels_binary = []\n",
    "\n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        audio, _ = librosa.load(file_path, sr=sr, mono=True)\n",
    "        num_segments = (audio.shape[0] // chunk_floats)\n",
    "        split_audio = np.array_split(audio[:num_segments * chunk_floats], num_segments)\n",
    "        samples.extend(split_audio)\n",
    "        samples_types.extend([types[i]] * len(split_audio))\n",
    "        samples_labels.extend([labels[i]] * len(split_audio))\n",
    "        samples_labels_binary.extend([labels_binary[i]] * len(split_audio))\n",
    "\n",
    "    samples = np.array(samples)\n",
    "    samples = samples[:, :, None]\n",
    "\n",
    "    samples_types = np.array(samples_types)\n",
    "    samples_labels = np.array(samples_labels)\n",
    "    samples_labels_binary = np.array(samples_labels_binary)\n",
    "\n",
    "    return samples, samples_types, samples_labels, samples_labels_binary\n",
    "\n",
    "print(\"[INFO] preparing data...\")\n",
    "samples, samples_types, samples_labels, samples_labels_binary = prepare_audio_set(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11953, 240000, 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples = samples[samples_types == 0]\n",
    "training_labels = samples_labels_binary[samples_types == 0]\n",
    "\n",
    "test_samples = samples[samples_types == 1]\n",
    "test_labels = samples_labels_binary[samples_types == 1]\n",
    "\n",
    "val_samples = samples[samples_types == 2]\n",
    "val_labels = samples_labels_binary[samples_types == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] constructing training/testing split...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "    \n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size=16):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(self.x.shape[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inds = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = self.x[inds]\n",
    "        batch_y = self.y[inds]\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "print(\"[INFO] constructing training/testing split...\")\n",
    "train_gen = DataGenerator(training_samples, training_labels, 64)\n",
    "test_gen = DataGenerator(test_samples, test_labels, 64)\n",
    "val_gen = DataGenerator(val_samples, val_labels, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] fitting model...\n",
      "Epoch 1/200\n",
      "100/100 [==============================] - 16s 148ms/step - loss: 48.7710 - accuracy: 0.4993 - val_loss: 35.7168 - val_accuracy: 0.6027\n",
      "Epoch 2/200\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 26.6533 - accuracy: 0.5588 - val_loss: 19.9702 - val_accuracy: 0.3973\n",
      "Epoch 3/200\n",
      "100/100 [==============================] - 15s 149ms/step - loss: 14.8177 - accuracy: 0.6224 - val_loss: 11.6379 - val_accuracy: 0.3973\n",
      "Epoch 4/200\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 8.4815 - accuracy: 0.6503 - val_loss: 7.1743 - val_accuracy: 0.3973\n",
      "Epoch 5/200\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 5.0573 - accuracy: 0.6590 - val_loss: 4.3883 - val_accuracy: 0.5415\n",
      "Epoch 6/200\n",
      "100/100 [==============================] - 15s 154ms/step - loss: 3.1836 - accuracy: 0.6645 - val_loss: 3.4483 - val_accuracy: 0.6027\n",
      "Epoch 7/200\n",
      "100/100 [==============================] - 15s 155ms/step - loss: 2.1112 - accuracy: 0.7053 - val_loss: 3.0921 - val_accuracy: 0.6027\n",
      "Epoch 8/200\n",
      "100/100 [==============================] - 16s 156ms/step - loss: 1.4911 - accuracy: 0.7345 - val_loss: 2.3143 - val_accuracy: 0.6027\n",
      "Epoch 9/200\n",
      "100/100 [==============================] - 16s 155ms/step - loss: 1.1213 - accuracy: 0.7579 - val_loss: 2.4937 - val_accuracy: 0.5859\n",
      "Epoch 10/200\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.8839 - accuracy: 0.7859 - val_loss: 1.7072 - val_accuracy: 0.5981\n",
      "Epoch 11/200\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.7313 - accuracy: 0.8026 - val_loss: 2.1493 - val_accuracy: 0.5729\n",
      "Epoch 12/200\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.6306 - accuracy: 0.8047 - val_loss: 1.2420 - val_accuracy: 0.5314\n",
      "Epoch 13/200\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 0.5648 - accuracy: 0.8045 - val_loss: 1.6830 - val_accuracy: 0.4413\n",
      "Epoch 14/200\n",
      "100/100 [==============================] - 16s 156ms/step - loss: 0.5040 - accuracy: 0.8215 - val_loss: 3.8258 - val_accuracy: 0.4137\n",
      "Epoch 15/200\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 0.4589 - accuracy: 0.8370 - val_loss: 1.7952 - val_accuracy: 0.5851\n",
      "Epoch 16/200\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 0.4298 - accuracy: 0.8401 - val_loss: 1.6900 - val_accuracy: 0.4220\n",
      "Epoch 17/200\n",
      "100/100 [==============================] - 16s 156ms/step - loss: 0.4020 - accuracy: 0.8498 - val_loss: 1.3563 - val_accuracy: 0.5641\n",
      "Epoch 18/200\n",
      "100/100 [==============================] - 16s 156ms/step - loss: 0.3768 - accuracy: 0.8614 - val_loss: 1.8231 - val_accuracy: 0.5834\n",
      "Epoch 19/200\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 0.3527 - accuracy: 0.8714 - val_loss: 1.8985 - val_accuracy: 0.6002\n",
      "Epoch 20/200\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.3406 - accuracy: 0.8647 - val_loss: 2.6226 - val_accuracy: 0.4195\n",
      "Epoch 21/200\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.3257 - accuracy: 0.8775 - val_loss: 1.6365 - val_accuracy: 0.4807\n",
      "Epoch 22/200\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 0.3096 - accuracy: 0.8858 - val_loss: 2.6100 - val_accuracy: 0.4179\n",
      "Epoch 23/200\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 0.2963 - accuracy: 0.8880 - val_loss: 1.6991 - val_accuracy: 0.4132\n",
      "Epoch 24/200\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.2797 - accuracy: 0.8976 - val_loss: 2.1068 - val_accuracy: 0.5448\n",
      "Epoch 25/200\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.2683 - accuracy: 0.9045 - val_loss: 3.8308 - val_accuracy: 0.4003\n",
      "Epoch 26/200\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.2625 - accuracy: 0.9015 - val_loss: 1.7773 - val_accuracy: 0.3973\n",
      "Epoch 27/200\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 0.2518 - accuracy: 0.9058 - val_loss: 3.2314 - val_accuracy: 0.4187\n",
      "Epoch 28/200\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.2516 - accuracy: 0.8972 - val_loss: 2.1510 - val_accuracy: 0.3734\n",
      "Epoch 29/200\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 0.2391 - accuracy: 0.9076 - val_loss: 1.4116 - val_accuracy: 0.4275\n",
      "Epoch 30/200\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.2326 - accuracy: 0.9134 - val_loss: 2.3147 - val_accuracy: 0.5809\n",
      "Epoch 31/200\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.2330 - accuracy: 0.9044 - val_loss: 1.3731 - val_accuracy: 0.4778\n",
      "Epoch 32/200\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.2246 - accuracy: 0.9094 - val_loss: 2.7287 - val_accuracy: 0.4049\n"
     ]
    }
   ],
   "source": [
    "from kapre.composed import get_melspectrogram_layer\n",
    "from kapre import LogmelToMFCC\n",
    "\n",
    "combination = (32, 64, 128, 256, 192)\n",
    "mylambda = 0.1\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    get_melspectrogram_layer(n_fft=400, hop_length=160, input_data_format='channels_last', output_data_format='channels_last'\n",
    "                                       , input_shape=(chunk_floats, 1), sample_rate=16000, return_decibel=True, n_mels= 26),\n",
    "    LogmelToMFCC(n_mfccs=40),\n",
    "\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "\n",
    "    tf.keras.layers.Conv2D(combination[0], (3, 3), activation='relu', kernel_regularizer = tf.keras.regularizers.l2(mylambda), padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(combination[1], (3, 3), activation='relu', kernel_regularizer = tf.keras.regularizers.l2(mylambda), padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(combination[2], (3, 3), activation='relu', kernel_regularizer = tf.keras.regularizers.l2(mylambda), padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(combination[3], (3, 3), activation='relu', kernel_regularizer = tf.keras.regularizers.l2(mylambda), padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "\n",
    "\n",
    "    tf.keras.layers.Conv2D(combination[4], (3, 3), activation='relu', kernel_regularizer = tf.keras.regularizers.l2(mylambda), padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer = tf.keras.regularizers.l2(mylambda)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta=0, restore_best_weights=True)\n",
    "\n",
    "print(\"[INFO] fitting model...\")\n",
    "history = model.fit(train_gen, epochs=200, validation_data=val_gen, callbacks=[early_stopping], verbose = 1, class_weight={0: .28, 1: .72}) # , class_weight={0: .25, 1:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Label = 0\n",
      "Min Prediction = 0.02110052\n",
      "Max Prediction = 0.10322046\n",
      "Mean Prediction = 0.058699366\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.0033402515\n",
      "Max Prediction = 0.30538842\n",
      "Mean Prediction = 0.045766268\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.024381027\n",
      "Max Prediction = 0.7800975\n",
      "Mean Prediction = 0.23049656\n",
      "--------------------------------------------\n",
      "True Label = 1\n",
      "Min Prediction = 0.27553907\n",
      "Max Prediction = 0.88052225\n",
      "Mean Prediction = 0.5702885\n",
      "--------------------------------------------\n",
      "True Label = 1\n",
      "Min Prediction = 0.106617555\n",
      "Max Prediction = 0.7931887\n",
      "Mean Prediction = 0.3410061\n",
      "--------------------------------------------\n",
      "True Label = 1\n",
      "Min Prediction = 0.037092187\n",
      "Max Prediction = 0.8245288\n",
      "Mean Prediction = 0.3301889\n",
      "--------------------------------------------\n",
      "True Label = 1\n",
      "Min Prediction = 0.2865608\n",
      "Max Prediction = 0.93598014\n",
      "Mean Prediction = 0.6841847\n",
      "--------------------------------------------\n",
      "True Label = 1\n",
      "Min Prediction = 0.1197349\n",
      "Max Prediction = 0.8077005\n",
      "Mean Prediction = 0.44801202\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.08148665\n",
      "Max Prediction = 0.77432525\n",
      "Mean Prediction = 0.34828106\n",
      "--------------------------------------------\n",
      "True Label = 1\n",
      "Min Prediction = 0.1758752\n",
      "Max Prediction = 0.85957974\n",
      "Mean Prediction = 0.551123\n",
      "--------------------------------------------\n",
      "True Label = 1\n",
      "Min Prediction = 0.09101709\n",
      "Max Prediction = 0.6311121\n",
      "Mean Prediction = 0.34731096\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.05277812\n",
      "Max Prediction = 0.80396664\n",
      "Mean Prediction = 0.342841\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.23290096\n",
      "Max Prediction = 0.7377167\n",
      "Mean Prediction = 0.49308297\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.11082459\n",
      "Max Prediction = 0.8739209\n",
      "Mean Prediction = 0.55559385\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.17501079\n",
      "Max Prediction = 0.8121618\n",
      "Mean Prediction = 0.55301213\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.10036415\n",
      "Max Prediction = 0.8474733\n",
      "Mean Prediction = 0.4237117\n",
      "--------------------------------------------\n",
      "True Label = 1\n",
      "Min Prediction = 0.09685987\n",
      "Max Prediction = 0.82457787\n",
      "Mean Prediction = 0.31666058\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.14467101\n",
      "Max Prediction = 0.7442285\n",
      "Mean Prediction = 0.39424646\n",
      "--------------------------------------------\n",
      "True Label = 1\n",
      "Min Prediction = 0.075172156\n",
      "Max Prediction = 0.74867165\n",
      "Mean Prediction = 0.30737004\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.42433134\n",
      "Max Prediction = 0.9699028\n",
      "Mean Prediction = 0.74828196\n",
      "--------------------------------------------\n",
      "True Label = 1\n",
      "Min Prediction = 0.11897687\n",
      "Max Prediction = 0.7347127\n",
      "Mean Prediction = 0.30967852\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.079700254\n",
      "Max Prediction = 0.76214695\n",
      "Mean Prediction = 0.29537022\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.06499284\n",
      "Max Prediction = 0.7365474\n",
      "Mean Prediction = 0.3119618\n",
      "--------------------------------------------\n",
      "True Label = 1\n",
      "Min Prediction = 0.071402594\n",
      "Max Prediction = 0.8641069\n",
      "Mean Prediction = 0.43145362\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.3671951\n",
      "Max Prediction = 0.98754495\n",
      "Mean Prediction = 0.8519267\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.09113971\n",
      "Max Prediction = 0.7055469\n",
      "Mean Prediction = 0.36995953\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.16857067\n",
      "Max Prediction = 0.7636874\n",
      "Mean Prediction = 0.48230916\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.21610896\n",
      "Max Prediction = 0.7867903\n",
      "Mean Prediction = 0.47941798\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.28460014\n",
      "Max Prediction = 0.85312885\n",
      "Mean Prediction = 0.56184447\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.16491108\n",
      "Max Prediction = 0.8936941\n",
      "Mean Prediction = 0.48325017\n",
      "--------------------------------------------\n",
      "True Label = 1\n",
      "Min Prediction = 0.0633956\n",
      "Max Prediction = 0.86986035\n",
      "Mean Prediction = 0.41233754\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.12309417\n",
      "Max Prediction = 0.7397411\n",
      "Mean Prediction = 0.34887096\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.068973675\n",
      "Max Prediction = 0.83892673\n",
      "Mean Prediction = 0.37893605\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.1583656\n",
      "Max Prediction = 0.6379157\n",
      "Mean Prediction = 0.3173137\n",
      "--------------------------------------------\n",
      "True Label = 0\n",
      "Min Prediction = 0.10526282\n",
      "Max Prediction = 0.6218282\n",
      "Mean Prediction = 0.27444044\n",
      "--------------------------------------------\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "means = []\n",
    "\n",
    "file_ids = os.listdir(\"edaicwoz/merge\")\n",
    "test_label_file = pd.read_csv(f\"daicwoz/dev_split.csv\")\n",
    "\n",
    "for file_id in val_labels_df[\"Participant_ID\"].values:\n",
    "    samples_test = []\n",
    "    file_path = os.path.join(data_dir, str(file_id), str(file_id) + \"_AUDIO.wav\")\n",
    "    audio, _ = librosa.load(file_path, sr=sr, mono=True)\n",
    "    num_segments = (audio.shape[0] // chunk_floats)\n",
    "    split_audio = np.array_split(audio[:num_segments * chunk_floats], num_segments)\n",
    "    samples_test.extend(split_audio)\n",
    "    samples_test = np.array(samples_test)\n",
    "    samples_test = samples_test[:, :, None]\n",
    "    print(\"True Label = \" + str(val_labels_df[val_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Binary'].values[0]))\n",
    "    predictions = model.predict(samples_test, verbose=0)\n",
    "    print(\"Min Prediction = \" + str(predictions.min()))\n",
    "    print(\"Max Prediction = \" + str(predictions.max()))\n",
    "    print(\"Mean Prediction = \" + str(predictions.mean()))\n",
    "    # print(predictions)\n",
    "    print(\"--------------------------------------------\")\n",
    "\n",
    "print(means)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
