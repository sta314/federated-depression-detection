{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r744gux56lPI",
        "outputId": "290cad2e-c31e-4264-e708-b739ace8d0c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.2/219.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr[simulation]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QhYdGQVU6py4"
      },
      "outputs": [],
      "source": [
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "from flwr.common.typing import NDArrays, Scalar\n",
        "from collections import OrderedDict\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUTPz2ww8yDy",
        "outputId": "1f4c62ce-d69e-482b-fc96-fba57611a3ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')#, force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if3RTu9E8zUl",
        "outputId": "8993099b-377f-4140-df34-6022408cdb1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/daic/ProjectPrototype\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/daic/ProjectPrototype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJsOdA0d80eO",
        "outputId": "32003766-9b8f-4c0e-c0b7-16dfc6922300"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'212148conf copy 3.ipynb'   edaicwoz   MFCCs_1030   MFCCs_1030.zip   preprocess_data.ipynb\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NOdo724P811N"
      },
      "outputs": [],
      "source": [
        "train_labels_df = pd.read_csv(\"edaicwoz/train_split.csv\")\n",
        "test_labels_df = pd.read_csv(\"edaicwoz/test_split.csv\")\n",
        "val_labels_df = pd.read_csv(\"edaicwoz/dev_split.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4TEHAQf083qj"
      },
      "outputs": [],
      "source": [
        "def load_audio_files(data_dir, sr=16000):\n",
        "    file_ids = os.listdir(data_dir)\n",
        "    subject_ids = []\n",
        "    file_paths = []\n",
        "    types = []\n",
        "    labels = []\n",
        "    labels_binary = []\n",
        "\n",
        "    for file_id in file_ids:\n",
        "        file_id = file_id.split(\"_\")[0]\n",
        "        file_path = [data_dir + \"/\" + file_id + \"/\" + file_id + \"_MFCC_\" + str(i) + \".npy\" for i in range(len(next(iter(enumerate(os.walk(data_dir + \"/\" + str(file_id) + \"/\"))))[1][2]))]\n",
        "        if int(file_id) in train_labels_df[\"Participant_ID\"].values:\n",
        "            types.append(0)\n",
        "            labels.append(train_labels_df[train_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Score'].values[0])\n",
        "            labels_binary.append(train_labels_df[train_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Binary'].values[0])\n",
        "\n",
        "        elif int(file_id) in test_labels_df[\"Participant_ID\"].values:\n",
        "            types.append(1)\n",
        "            labels.append(test_labels_df[test_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Score'].values[0])\n",
        "            labels_binary.append(test_labels_df[test_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Binary'].values[0])\n",
        "        else:\n",
        "            types.append(2)\n",
        "            labels.append(val_labels_df[val_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Score'].values[0])\n",
        "            labels_binary.append(val_labels_df[val_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Binary'].values[0])\n",
        "        subject_ids.append(int(file_id))\n",
        "        file_paths.append(file_path)\n",
        "\n",
        "    return file_ids, subject_ids, file_paths, types, labels, labels_binary\n",
        "\n",
        "data_dir = \"MFCCs_1030\"\n",
        "\n",
        "file_ids, subject_ids, file_paths, types, labels, labels_binary = load_audio_files(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f54IRuEk889P",
        "outputId": "9a7eab02-4201-4ea1-f60e-3a795394fe69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] preparing data...\n"
          ]
        }
      ],
      "source": [
        "def prepare_audio_set(file_paths):\n",
        "\n",
        "    samples = []\n",
        "    samples_ids = []\n",
        "    samples_types = []\n",
        "    samples_labels = []\n",
        "    samples_labels_binary = []\n",
        "\n",
        "    for i, file_path in enumerate(file_paths):\n",
        "        all_mfccs = []\n",
        "        for j in range(len(file_path)):\n",
        "            all_mfccs.append(np.load(file_path[j]))\n",
        "        all_mfccs = np.array(all_mfccs)\n",
        "        samples.extend(all_mfccs)\n",
        "        samples_ids.extend([subject_ids[i]] * len(all_mfccs))\n",
        "        samples_types.extend([types[i]] * len(all_mfccs))\n",
        "        samples_labels.extend([labels[i]] * len(all_mfccs))\n",
        "        samples_labels_binary.extend([labels_binary[i]] * len(all_mfccs))\n",
        "\n",
        "    samples = np.array(samples)\n",
        "\n",
        "    samples_ids = np.array(samples_ids)\n",
        "    samples_types = np.array(samples_types)\n",
        "    samples_labels = np.array(samples_labels)\n",
        "    samples_labels_binary = np.array(samples_labels_binary)\n",
        "\n",
        "    return samples, samples_ids, samples_types, samples_labels, samples_labels_binary\n",
        "\n",
        "print(\"[INFO] preparing data...\")\n",
        "samples, samples_ids, samples_types, samples_labels, samples_labels_binary = prepare_audio_set(file_paths)\n",
        "samples = np.swapaxes(samples, 1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uMLrvS1L9F8v"
      },
      "outputs": [],
      "source": [
        "training_samples = samples[samples_types == 0]\n",
        "training_labels = samples_labels_binary[samples_types == 0]\n",
        "training_subject_ids = samples_ids[samples_types == 0]\n",
        "\n",
        "test_samples = samples[samples_types == 1]\n",
        "test_labels = samples_labels_binary[samples_types == 1]\n",
        "\n",
        "val_samples = samples[samples_types == 2]\n",
        "val_labels_df = samples_labels_binary[samples_types == 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bpe1dRB-8WdZ"
      },
      "outputs": [],
      "source": [
        "del samples, samples_ids, samples_types, samples_labels, samples_labels_binary\n",
        "del file_ids, subject_ids, file_paths, types, labels, labels_binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PDSzvY3L6woq"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "NUM_CLIENTS = 4\n",
        "BATCH_SIZE = 32\n",
        "NUM_ROUNDS = 5\n",
        "DEPRESSIVE_MULTIPLIER = 30\n",
        "NON_DEPRESSIVE_MULTIPLIER = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoLCYLk-60oa",
        "outputId": "6bf544f6-8963-414b-d049-39db31621990"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-466285f35f26>:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  training_samples_grouped = np.array(training_samples_grouped)\n"
          ]
        }
      ],
      "source": [
        "def partition_data(X: np.ndarray, X_ids: np.ndarray, n_clients: int, d_mult: int, n_d_mult: int) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
        "\n",
        "    unique_subject_ids, counts = np.unique(X_ids, return_counts=True)\n",
        "\n",
        "    # grouping the training samples by patient\n",
        "    training_samples_grouped = []\n",
        "    for i in unique_subject_ids:\n",
        "        training_samples_grouped.append(X[X_ids == i])\n",
        "    training_samples_grouped = np.array(training_samples_grouped)\n",
        "\n",
        "    mask_30_segments = np.array([sample.shape[0] == DEPRESSIVE_MULTIPLIER for sample in training_samples_grouped])\n",
        "\n",
        "    # creating masks to get deppressives and non deppressives\n",
        "    mask_10_segments = np.array([sample.shape[0] == NON_DEPRESSIVE_MULTIPLIER for sample in training_samples_grouped])\n",
        "\n",
        "    data_array_30_segments = training_samples_grouped[mask_30_segments]\n",
        "\n",
        "    data_array_10_segments = training_samples_grouped[mask_10_segments]\n",
        "\n",
        "    # recreating labels\n",
        "    X_train_zeros = np.array_split(data_array_10_segments, NUM_CLIENTS)\n",
        "    X_train_ones = np.array_split(data_array_30_segments, NUM_CLIENTS)\n",
        "\n",
        "    # concatenating splitted ones and zeros with labels\n",
        "    X_train_splitted = [] # (NUM_CLIENTS, data)\n",
        "    y_train_splitted = [] # (NUM_CLIENTS, labels)\n",
        "    for i in range(NUM_CLIENTS):\n",
        "\n",
        "        # stack the segments from groups then concatenate\n",
        "        client_data = np.concatenate((np.vstack(X_train_zeros[i]), np.vstack(X_train_ones[i])), axis=0)\n",
        "        client_labels = np.concatenate((np.zeros((X_train_zeros[i].shape[0] * NON_DEPRESSIVE_MULTIPLIER), dtype=int), np.ones((X_train_ones[i].shape[0] * DEPRESSIVE_MULTIPLIER), dtype=int)), axis=0)\n",
        "\n",
        "        X_train_splitted.append(client_data)\n",
        "        y_train_splitted.append(client_labels)\n",
        "\n",
        "    return X_train_splitted, y_train_splitted\n",
        "\n",
        "X_trains, y_trains = partition_data(training_samples, training_subject_ids, NUM_CLIENTS, DEPRESSIVE_MULTIPLIER, NON_DEPRESSIVE_MULTIPLIER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0CIVmuPtAV9R"
      },
      "outputs": [],
      "source": [
        "del training_samples, training_labels, training_subject_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOakTnvyGeG9",
        "outputId": "0536affa-2519-405d-c4ee-e825b90ea146"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(610, 15001, 13)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_trains[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6TLISBYkEXxm"
      },
      "outputs": [],
      "source": [
        "def get_model(input_shape):\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.GRU(units = 64, input_shape = input_shape))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "NqrDDSKP7HtP"
      },
      "outputs": [],
      "source": [
        "from flwr.common.typing import NDArrays\n",
        "# creating clients code\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "\n",
        "    def __init__(self, model: tf.keras.models.Sequential, X_train: np.ndarray, y_train: np.ndarray):\n",
        "        self.model = model\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return self.model.get_weights()\n",
        "\n",
        "\n",
        "    def fit(self, parameters: NDArrays, config: Dict[str, Scalar]) -> NDArrays:\n",
        "\n",
        "        # compile the model\n",
        "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1), metrics=['accuracy'])\n",
        "\n",
        "        # assign weights\n",
        "        self.model.set_weights(parameters)\n",
        "\n",
        "        # train for the client using its data\n",
        "        history = self.model.fit(self.X_train, self.y_train , epochs=1, verbose=0)\n",
        "        results = {\n",
        "            \"loss\": history.history[\"loss\"][0],\n",
        "            \"accuracy\": history.history[\"accuracy\"][0],\n",
        "        }\n",
        "        return self.model.get_weights(), len(self.X_train), results\n",
        "\n",
        "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar])-> Tuple[float, int, Dict[str, Scalar]]:\n",
        "        return 1.2, len(self.X_train), {\"accuracy\": 0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "qgf9oz_57I9I"
      },
      "outputs": [],
      "source": [
        "# client creator by client id\n",
        "def create_client_fn(cid: str) -> FlowerClient:\n",
        "\n",
        "    input_shape = (15001, 13)\n",
        "    model = get_model(input_shape)\n",
        "    cid_int = int(cid)\n",
        "    return FlowerClient(model, X_trains[cid_int], y_trains[cid_int])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-BT6BuAA7J3j"
      },
      "outputs": [],
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    return {\"accuracy\": 0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l4S_aJJ7Laq",
        "outputId": "0588e03a-c4de-41e6-ccac-8541fa1c9d9a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2023-12-10 17:02:47,803 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=25, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=25, round_timeout=None)\n",
            "2023-12-10 17:02:52,004\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2023-12-10 17:02:53,551 | app.py:213 | Flower VCE: Ray initialized with resources: {'memory': 32677203150.0, 'object_store_memory': 16338601574.0, 'accelerator_type:V100': 1.0, 'node:__internal_head__': 1.0, 'CPU': 8.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'memory': 32677203150.0, 'object_store_memory': 16338601574.0, 'accelerator_type:V100': 1.0, 'node:__internal_head__': 1.0, 'CPU': 8.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0}\n",
            "INFO flwr 2023-12-10 17:02:53,553 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO flwr 2023-12-10 17:02:53,555 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 2, 'num_gpus': 1}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 2, 'num_gpus': 1}\n",
            "INFO flwr 2023-12-10 17:02:53,575 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
            "INFO flwr 2023-12-10 17:02:53,577 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-12-10 17:02:53,581 | server.py:276 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=55596)\u001b[0m 2023-12-10 17:02:54.670973: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=55596)\u001b[0m 2023-12-10 17:02:54.671028: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=55596)\u001b[0m 2023-12-10 17:02:54.671063: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=55596)\u001b[0m 2023-12-10 17:02:55.806932: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=55596)\u001b[0m 2023-12-10 17:03:02.562215: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO flwr 2023-12-10 17:03:02,945 | server.py:280 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-12-10 17:03:02,947 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-12-10 17:03:11,462 | server.py:94 | initial parameters (loss, other metrics): 0.6965839266777039, {'accuracy': 0.550000011920929}\n",
            "INFO:flwr:initial parameters (loss, other metrics): 0.6965839266777039, {'accuracy': 0.550000011920929}\n",
            "INFO flwr 2023-12-10 17:03:11,464 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-12-10 17:03:11,465 | server.py:222 | fit_round 1: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-12-10 17:04:25,806 | server.py:236 | fit_round 1 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 4 results and 0 failures\n",
            "WARNING flwr 2023-12-10 17:04:25,817 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "INFO flwr 2023-12-10 17:04:34,086 | server.py:125 | fit progress: (1, 0.6689485311508179, {'accuracy': 0.5612499713897705}, 82.62076858799992)\n",
            "INFO:flwr:fit progress: (1, 0.6689485311508179, {'accuracy': 0.5612499713897705}, 82.62076858799992)\n",
            "INFO flwr 2023-12-10 17:04:34,089 | server.py:171 | evaluate_round 1: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 1: no clients selected, cancel\n",
            "DEBUG flwr 2023-12-10 17:04:34,094 | server.py:222 | fit_round 2: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-12-10 17:05:44,244 | server.py:236 | fit_round 2 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 4 results and 0 failures\n",
            "INFO flwr 2023-12-10 17:05:52,536 | server.py:125 | fit progress: (2, 0.6633371114730835, {'accuracy': 0.6000000238418579}, 161.07055176799986)\n",
            "INFO:flwr:fit progress: (2, 0.6633371114730835, {'accuracy': 0.6000000238418579}, 161.07055176799986)\n",
            "INFO flwr 2023-12-10 17:05:52,538 | server.py:171 | evaluate_round 2: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 2: no clients selected, cancel\n",
            "DEBUG flwr 2023-12-10 17:05:52,542 | server.py:222 | fit_round 3: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-12-10 17:07:01,749 | server.py:236 | fit_round 3 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 4 results and 0 failures\n",
            "INFO flwr 2023-12-10 17:07:10,030 | server.py:125 | fit progress: (3, 0.6643823385238647, {'accuracy': 0.6112499833106995}, 238.564980733001)\n",
            "INFO:flwr:fit progress: (3, 0.6643823385238647, {'accuracy': 0.6112499833106995}, 238.564980733001)\n",
            "INFO flwr 2023-12-10 17:07:10,032 | server.py:171 | evaluate_round 3: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 3: no clients selected, cancel\n",
            "DEBUG flwr 2023-12-10 17:07:10,035 | server.py:222 | fit_round 4: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-12-10 17:08:21,268 | server.py:236 | fit_round 4 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 4 results and 0 failures\n",
            "INFO flwr 2023-12-10 17:08:29,599 | server.py:125 | fit progress: (4, 0.6652672290802002, {'accuracy': 0.6200000047683716}, 318.1339371110007)\n",
            "INFO:flwr:fit progress: (4, 0.6652672290802002, {'accuracy': 0.6200000047683716}, 318.1339371110007)\n",
            "INFO flwr 2023-12-10 17:08:29,603 | server.py:171 | evaluate_round 4: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 4: no clients selected, cancel\n",
            "DEBUG flwr 2023-12-10 17:08:29,606 | server.py:222 | fit_round 5: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-12-10 17:09:39,579 | server.py:236 | fit_round 5 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 4 results and 0 failures\n",
            "INFO flwr 2023-12-10 17:09:48,022 | server.py:125 | fit progress: (5, 0.6660997271537781, {'accuracy': 0.625}, 396.5570663090002)\n",
            "INFO:flwr:fit progress: (5, 0.6660997271537781, {'accuracy': 0.625}, 396.5570663090002)\n",
            "INFO flwr 2023-12-10 17:09:48,025 | server.py:171 | evaluate_round 5: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 5: no clients selected, cancel\n",
            "DEBUG flwr 2023-12-10 17:09:48,027 | server.py:222 | fit_round 6: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 6: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-12-10 17:10:56,486 | server.py:236 | fit_round 6 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 6 received 4 results and 0 failures\n",
            "INFO flwr 2023-12-10 17:11:04,944 | server.py:125 | fit progress: (6, 0.6676099896430969, {'accuracy': 0.6262500286102295}, 473.47877203900134)\n",
            "INFO:flwr:fit progress: (6, 0.6676099896430969, {'accuracy': 0.6262500286102295}, 473.47877203900134)\n",
            "INFO flwr 2023-12-10 17:11:04,946 | server.py:171 | evaluate_round 6: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 6: no clients selected, cancel\n",
            "DEBUG flwr 2023-12-10 17:11:04,950 | server.py:222 | fit_round 7: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 7: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-12-10 17:12:15,169 | server.py:236 | fit_round 7 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 7 received 4 results and 0 failures\n",
            "INFO flwr 2023-12-10 17:12:23,447 | server.py:125 | fit progress: (7, 0.6667397022247314, {'accuracy': 0.6237499713897705}, 551.9817190980011)\n",
            "INFO:flwr:fit progress: (7, 0.6667397022247314, {'accuracy': 0.6237499713897705}, 551.9817190980011)\n",
            "INFO flwr 2023-12-10 17:12:23,449 | server.py:171 | evaluate_round 7: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 7: no clients selected, cancel\n",
            "DEBUG flwr 2023-12-10 17:12:23,451 | server.py:222 | fit_round 8: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 8: strategy sampled 4 clients (out of 4)\n",
            "DEBUG flwr 2023-12-10 17:13:33,840 | server.py:236 | fit_round 8 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 8 received 4 results and 0 failures\n",
            "INFO flwr 2023-12-10 17:13:42,298 | server.py:125 | fit progress: (8, 0.6656036972999573, {'accuracy': 0.6162499785423279}, 630.8325014460006)\n",
            "INFO:flwr:fit progress: (8, 0.6656036972999573, {'accuracy': 0.6162499785423279}, 630.8325014460006)\n",
            "INFO flwr 2023-12-10 17:13:42,301 | server.py:171 | evaluate_round 8: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 8: no clients selected, cancel\n",
            "DEBUG flwr 2023-12-10 17:13:42,304 | server.py:222 | fit_round 9: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 9: strategy sampled 4 clients (out of 4)\n"
          ]
        }
      ],
      "source": [
        "best_accuracy = 0.0\n",
        "best_loss = 999\n",
        "weights = np.array([])\n",
        "def evaluate(\n",
        "    server_round: int,\n",
        "    parameters: fl.common.NDArrays,\n",
        "    config: Dict[str, fl.common.Scalar],\n",
        "    ) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "    \"\"\"Centralized evaluation function\"\"\"\n",
        "\n",
        "    input_shape = (15001, 13)\n",
        "    model = get_model(input_shape)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1), metrics=['accuracy'])\n",
        "    model.set_weights(parameters)\n",
        "\n",
        "    loss, accuracy = model.evaluate(val_samples, val_labels_df, batch_size=16, verbose=0)\n",
        "\n",
        "    global best_accuracy\n",
        "    global best_loss\n",
        "    global weights\n",
        "\n",
        "    if loss < best_loss:\n",
        "        best_accuracy = accuracy\n",
        "        weights = parameters\n",
        "        best_loss = loss\n",
        "\n",
        "    return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "\n",
        "client_resources = {\"num_cpus\": 2}\n",
        "if tf.config.get_visible_devices(\"GPU\"):\n",
        "    client_resources[\"num_gpus\"] = 1\n",
        "\n",
        "# Specify the Strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "    fraction_evaluate=0.0,\n",
        "    min_fit_clients=NUM_CLIENTS,\n",
        "    min_available_clients=NUM_CLIENTS,  # Wait until all 8 clients are available\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,\n",
        "    evaluate_fn=evaluate\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "history = fl.simulation.start_simulation(\n",
        "    client_fn=create_client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=25),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO-YYWSD7NcS",
        "outputId": "05ab7d11-715f-42a3-a58c-75a0c6f52f3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "History (loss, centralized):\n",
              "\tround 0: 0.7060863375663757\n",
              "\tround 1: 0.7022933959960938\n",
              "\tround 2: 0.7004526257514954\n",
              "\tround 3: 0.6980700492858887\n",
              "\tround 4: 0.6964865326881409\n",
              "\tround 5: 0.6952226758003235\n",
              "History (metrics, centralized):\n",
              "{'accuracy': [(0, 0.4962500035762787), (1, 0.4950000047683716), (2, 0.48625001311302185), (3, 0.5062500238418579), (4, 0.5149999856948853), (5, 0.5149999856948853)]}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-29DaJU7PWE"
      },
      "outputs": [],
      "source": [
        "# printing the validation results\n",
        "print(best_accuracy)\n",
        "print(weights)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "5addf786bcd861d1ce5006f23111f8cbb206731e5b61b0a5632ba9e0252558a8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
