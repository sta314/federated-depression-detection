{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df = pd.read_csv(\"edaicwoz/train_split.csv\")\n",
    "test_labels_df = pd.read_csv(\"edaicwoz/test_split.csv\")\n",
    "val_labels_df = pd.read_csv(\"edaicwoz/dev_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_files(data_dir, sr=16000):\n",
    "    file_ids = os.listdir(data_dir)\n",
    "    subject_ids = []\n",
    "    file_paths = []\n",
    "    types = []\n",
    "    labels = []\n",
    "    labels_binary = []\n",
    "\n",
    "    for file_id in file_ids:\n",
    "        file_id = file_id.split(\"_\")[0]\n",
    "        file_path = [data_dir + \"/\" + file_id + \"/\" + file_id + \"_MFCC_\" + str(i) + \".npy\" for i in range(len(next(iter(enumerate(os.walk(data_dir + \"/\" + str(file_id) + \"/\"))))[1][2]))]\n",
    "        if int(file_id) in train_labels_df[\"Participant_ID\"].values:\n",
    "            types.append(0)\n",
    "            labels.append(train_labels_df[train_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Score'].values[0])\n",
    "            labels_binary.append(train_labels_df[train_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Binary'].values[0])\n",
    "            \n",
    "        elif int(file_id) in test_labels_df[\"Participant_ID\"].values:\n",
    "            types.append(1)\n",
    "            labels.append(test_labels_df[test_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Score'].values[0])\n",
    "            labels_binary.append(test_labels_df[test_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Binary'].values[0])\n",
    "        else:\n",
    "            types.append(2)\n",
    "            labels.append(val_labels_df[val_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Score'].values[0])\n",
    "            labels_binary.append(val_labels_df[val_labels_df[\"Participant_ID\"] == int(file_id)]['PHQ_Binary'].values[0])\n",
    "        subject_ids.append(int(file_id))\n",
    "        file_paths.append(file_path)\n",
    "\n",
    "    return file_ids, subject_ids, file_paths, types, labels, labels_binary\n",
    "\n",
    "data_dir = \"MFCCs_1030\"\n",
    "\n",
    "file_ids, subject_ids, file_paths, types, labels, labels_binary = load_audio_files(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] preparing data...\n"
     ]
    }
   ],
   "source": [
    "def prepare_audio_set(file_paths):\n",
    "\n",
    "    samples = []\n",
    "    samples_ids = []\n",
    "    samples_types = []\n",
    "    samples_labels = []\n",
    "    samples_labels_binary = []\n",
    "\n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        all_mfccs = []\n",
    "        for j in range(len(file_path)):\n",
    "            all_mfccs.append(np.load(file_path[j]))\n",
    "        all_mfccs = np.array(all_mfccs)\n",
    "        samples.extend(all_mfccs)\n",
    "        samples_ids.extend([subject_ids[i]] * len(all_mfccs))\n",
    "        samples_types.extend([types[i]] * len(all_mfccs))\n",
    "        samples_labels.extend([labels[i]] * len(all_mfccs))\n",
    "        samples_labels_binary.extend([labels_binary[i]] * len(all_mfccs))\n",
    "\n",
    "    samples = np.array(samples)\n",
    "\n",
    "    samples_ids = np.array(samples_ids)\n",
    "    samples_types = np.array(samples_types)\n",
    "    samples_labels = np.array(samples_labels)\n",
    "    samples_labels_binary = np.array(samples_labels_binary)\n",
    "\n",
    "    return samples, samples_ids, samples_types, samples_labels, samples_labels_binary\n",
    "\n",
    "print(\"[INFO] preparing data...\")\n",
    "samples, samples_ids, samples_types, samples_labels, samples_labels_binary = prepare_audio_set(file_paths)\n",
    "samples = np.swapaxes(samples, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples = samples[samples_types == 0]\n",
    "training_labels = samples_labels_binary[samples_types == 0]\n",
    "training_subject_ids = samples_ids[samples_types == 0]\n",
    "\n",
    "test_samples = samples[samples_types == 1]\n",
    "test_labels = samples_labels_binary[samples_types == 1]\n",
    "\n",
    "val_samples = samples[samples_types == 2]\n",
    "val_labels_df = samples_labels_binary[samples_types == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2350, 15001, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] constructing training/testing split...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DataGeneratorVanilla(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size=256):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(self.x.shape[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inds = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = self.x[inds]\n",
    "        batch_y = self.y[inds]\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "print(\"[INFO] constructing training/testing split...\")\n",
    "train_gen = DataGeneratorVanilla(training_samples, training_labels, 32)\n",
    "test_gen = DataGeneratorVanilla(test_samples, test_labels, 32)\n",
    "val_gen = DataGeneratorVanilla(val_samples, val_labels_df, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1240"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(training_labels == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2350, 15001, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(training_samples.shape[0], training_samples.shape[1], training_samples.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_4 (GRU)                 (None, 64)                15168     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,281\n",
      "Trainable params: 17,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[INFO] fitting model...\n",
      "Epoch 1/100\n",
      "74/74 [==============================] - 51s 670ms/step - loss: 0.7325 - accuracy: 0.5030 - val_loss: 0.6934 - val_accuracy: 0.4900\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 49s 657ms/step - loss: 0.7184 - accuracy: 0.5132 - val_loss: 0.6902 - val_accuracy: 0.5263\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 49s 664ms/step - loss: 0.7020 - accuracy: 0.5272 - val_loss: 0.6890 - val_accuracy: 0.5200\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 49s 656ms/step - loss: 0.6929 - accuracy: 0.5353 - val_loss: 0.6859 - val_accuracy: 0.5225\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 49s 660ms/step - loss: 0.6783 - accuracy: 0.5753 - val_loss: 0.6858 - val_accuracy: 0.5275\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 46s 625ms/step - loss: 0.6727 - accuracy: 0.5783 - val_loss: 0.6841 - val_accuracy: 0.5175\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 49s 659ms/step - loss: 0.6695 - accuracy: 0.5868 - val_loss: 0.6833 - val_accuracy: 0.5225\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 49s 660ms/step - loss: 0.6600 - accuracy: 0.6094 - val_loss: 0.6803 - val_accuracy: 0.5387\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 49s 660ms/step - loss: 0.6504 - accuracy: 0.6230 - val_loss: 0.6815 - val_accuracy: 0.5612\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 49s 659ms/step - loss: 0.6489 - accuracy: 0.6345 - val_loss: 0.6823 - val_accuracy: 0.5450\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - 49s 659ms/step - loss: 0.6450 - accuracy: 0.6481 - val_loss: 0.6820 - val_accuracy: 0.5550\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - 49s 660ms/step - loss: 0.6451 - accuracy: 0.6357 - val_loss: 0.6820 - val_accuracy: 0.5437\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - 49s 662ms/step - loss: 0.6345 - accuracy: 0.6660 - val_loss: 0.6837 - val_accuracy: 0.5437\n",
      "[INFO] compiling model...\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_5 (GRU)                 (None, 64)                15168     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,281\n",
      "Trainable params: 17,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[INFO] fitting model...\n",
      "Epoch 1/100\n",
      "74/74 [==============================] - 58s 767ms/step - loss: 0.7224 - accuracy: 0.5345 - val_loss: 0.6620 - val_accuracy: 0.6250\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 53s 723ms/step - loss: 0.6846 - accuracy: 0.5638 - val_loss: 0.6600 - val_accuracy: 0.6125\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 55s 749ms/step - loss: 0.6553 - accuracy: 0.6196 - val_loss: 0.6625 - val_accuracy: 0.5938\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 54s 729ms/step - loss: 0.6240 - accuracy: 0.6860 - val_loss: 0.6587 - val_accuracy: 0.5975\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 54s 730ms/step - loss: 0.6030 - accuracy: 0.7153 - val_loss: 0.6544 - val_accuracy: 0.5962\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 52s 707ms/step - loss: 0.5863 - accuracy: 0.7260 - val_loss: 0.6661 - val_accuracy: 0.5800\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 53s 724ms/step - loss: 0.5653 - accuracy: 0.7587 - val_loss: 0.6877 - val_accuracy: 0.5663\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 53s 720ms/step - loss: 0.5466 - accuracy: 0.7681 - val_loss: 0.6977 - val_accuracy: 0.5400\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 54s 725ms/step - loss: 0.5190 - accuracy: 0.8038 - val_loss: 0.7105 - val_accuracy: 0.5312\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 55s 743ms/step - loss: 0.5043 - accuracy: 0.8077 - val_loss: 0.7365 - val_accuracy: 0.5500\n",
      "[INFO] compiling model...\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_6 (GRU)                 (None, 64)                15168     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,281\n",
      "Trainable params: 17,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[INFO] fitting model...\n",
      "Epoch 1/100\n",
      "74/74 [==============================] - 56s 744ms/step - loss: 0.7151 - accuracy: 0.5281 - val_loss: 0.6794 - val_accuracy: 0.5850\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 55s 749ms/step - loss: 0.6850 - accuracy: 0.5617 - val_loss: 0.6805 - val_accuracy: 0.5537\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 55s 744ms/step - loss: 0.6633 - accuracy: 0.6047 - val_loss: 0.6885 - val_accuracy: 0.5500\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 55s 741ms/step - loss: 0.6499 - accuracy: 0.6379 - val_loss: 0.6927 - val_accuracy: 0.4863\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 55s 742ms/step - loss: 0.6232 - accuracy: 0.6796 - val_loss: 0.6973 - val_accuracy: 0.4975\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 55s 745ms/step - loss: 0.6025 - accuracy: 0.7191 - val_loss: 0.7124 - val_accuracy: 0.5375\n",
      "[INFO] compiling model...\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_7 (GRU)                 (None, 64)                15168     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,281\n",
      "Trainable params: 17,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[INFO] fitting model...\n",
      "Epoch 1/100\n",
      "74/74 [==============================] - 57s 759ms/step - loss: 0.7080 - accuracy: 0.5391 - val_loss: 0.6957 - val_accuracy: 0.5238\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 55s 738ms/step - loss: 0.6512 - accuracy: 0.6000 - val_loss: 0.6771 - val_accuracy: 0.5813\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 54s 728ms/step - loss: 0.6033 - accuracy: 0.6826 - val_loss: 0.6944 - val_accuracy: 0.5525\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 54s 729ms/step - loss: 0.5650 - accuracy: 0.7379 - val_loss: 0.7155 - val_accuracy: 0.5850\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 56s 754ms/step - loss: 0.5147 - accuracy: 0.7855 - val_loss: 0.7704 - val_accuracy: 0.5450\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 54s 734ms/step - loss: 0.4753 - accuracy: 0.8213 - val_loss: 0.8093 - val_accuracy: 0.5600\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 54s 732ms/step - loss: 0.4478 - accuracy: 0.8430 - val_loss: 0.8170 - val_accuracy: 0.5650\n",
      "The learning rate with the lowest validation loss is 0.0003\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_model(input_shape):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.GRU(units = 64, input_shape = input_shape))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "histories = []\n",
    "learning_rates = [0.0001, 0.0003, 0.0005, 0.001]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = create_cnn_model((training_samples.shape[1], training_samples.shape[2]))\n",
    "\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1), metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    print(\"[INFO] fitting model...\")\n",
    "    history = model.fit(train_gen, epochs=100, validation_data=val_gen, callbacks=[early_stopping])\n",
    "\n",
    "    \n",
    "\n",
    "    histories.append(history)\n",
    "\n",
    "    del model\n",
    "\n",
    "lowest_loss = float('inf')\n",
    "lowest_loss_index = -1\n",
    "\n",
    "for i, history in enumerate(histories):\n",
    "    val_loss = history.history['val_loss'][-6] # we're using -6 since patience of early stopping is 5\n",
    "    if val_loss < lowest_loss:\n",
    "        lowest_loss = val_loss\n",
    "        lowest_loss_index = i\n",
    "\n",
    "print(f\"The learning rate with the lowest validation loss is {learning_rates[lowest_loss_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_30 (GRU)                (None, 64)                15168     \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,281\n",
      "Trainable params: 17,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[INFO] fitting model...\n",
      "Epoch 1/100\n",
      "74/74 [==============================] - 55s 734ms/step - loss: 0.7337 - accuracy: 0.5260 - val_loss: 0.7031 - val_accuracy: 0.5063\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 54s 734ms/step - loss: 0.6975 - accuracy: 0.5349 - val_loss: 0.7010 - val_accuracy: 0.5163\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 55s 738ms/step - loss: 0.6651 - accuracy: 0.5894 - val_loss: 0.6932 - val_accuracy: 0.5113\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 54s 732ms/step - loss: 0.6516 - accuracy: 0.6217 - val_loss: 0.6918 - val_accuracy: 0.5150\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 54s 725ms/step - loss: 0.6332 - accuracy: 0.6489 - val_loss: 0.6918 - val_accuracy: 0.5175\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 52s 706ms/step - loss: 0.6058 - accuracy: 0.6889 - val_loss: 0.6965 - val_accuracy: 0.5038\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 52s 698ms/step - loss: 0.5898 - accuracy: 0.6970 - val_loss: 0.6980 - val_accuracy: 0.5075\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 53s 717ms/step - loss: 0.5696 - accuracy: 0.7251 - val_loss: 0.6922 - val_accuracy: 0.5075\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 53s 710ms/step - loss: 0.5467 - accuracy: 0.7434 - val_loss: 0.7134 - val_accuracy: 0.4950\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 53s 720ms/step - loss: 0.5345 - accuracy: 0.7519 - val_loss: 0.7084 - val_accuracy: 0.5063\n",
      "[INFO] compiling model...\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_31 (GRU)                (None, 64)                15168     \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,281\n",
      "Trainable params: 17,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[INFO] fitting model...\n",
      "Epoch 1/100\n",
      "74/74 [==============================] - 54s 721ms/step - loss: 0.7777 - accuracy: 0.5132 - val_loss: 0.6879 - val_accuracy: 0.5125\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 53s 721ms/step - loss: 0.7184 - accuracy: 0.5328 - val_loss: 0.6818 - val_accuracy: 0.5450\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 53s 722ms/step - loss: 0.6947 - accuracy: 0.5472 - val_loss: 0.6790 - val_accuracy: 0.5575\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 53s 722ms/step - loss: 0.6809 - accuracy: 0.5617 - val_loss: 0.6771 - val_accuracy: 0.5312\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 54s 726ms/step - loss: 0.6621 - accuracy: 0.5928 - val_loss: 0.6889 - val_accuracy: 0.5250\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 53s 719ms/step - loss: 0.6363 - accuracy: 0.6421 - val_loss: 0.6870 - val_accuracy: 0.5263\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 53s 720ms/step - loss: 0.6249 - accuracy: 0.6604 - val_loss: 0.7017 - val_accuracy: 0.5100\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 54s 728ms/step - loss: 0.6091 - accuracy: 0.6932 - val_loss: 0.7075 - val_accuracy: 0.5213\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 53s 711ms/step - loss: 0.5900 - accuracy: 0.7217 - val_loss: 0.7237 - val_accuracy: 0.5138\n",
      "[INFO] compiling model...\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_32 (GRU)                (None, 64)                15168     \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,281\n",
      "Trainable params: 17,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[INFO] fitting model...\n",
      "Epoch 1/100\n",
      "74/74 [==============================] - 55s 735ms/step - loss: 0.7571 - accuracy: 0.5132 - val_loss: 0.7202 - val_accuracy: 0.4313\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 53s 716ms/step - loss: 0.7083 - accuracy: 0.5285 - val_loss: 0.6979 - val_accuracy: 0.4913\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 53s 722ms/step - loss: 0.6839 - accuracy: 0.5706 - val_loss: 0.7000 - val_accuracy: 0.5075\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 54s 735ms/step - loss: 0.6659 - accuracy: 0.6004 - val_loss: 0.6840 - val_accuracy: 0.5612\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 52s 711ms/step - loss: 0.6408 - accuracy: 0.6553 - val_loss: 0.6780 - val_accuracy: 0.5713\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 53s 718ms/step - loss: 0.6205 - accuracy: 0.6809 - val_loss: 0.6752 - val_accuracy: 0.5500\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 52s 708ms/step - loss: 0.6039 - accuracy: 0.7072 - val_loss: 0.6840 - val_accuracy: 0.5263\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 53s 719ms/step - loss: 0.5848 - accuracy: 0.7272 - val_loss: 0.6819 - val_accuracy: 0.5225\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 54s 734ms/step - loss: 0.5695 - accuracy: 0.7370 - val_loss: 0.6770 - val_accuracy: 0.5437\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 53s 720ms/step - loss: 0.5473 - accuracy: 0.7604 - val_loss: 0.6929 - val_accuracy: 0.5387\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - 54s 726ms/step - loss: 0.5271 - accuracy: 0.7872 - val_loss: 0.6839 - val_accuracy: 0.5450\n",
      "The label smoothing value with the lowest validation loss is 0.1\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_model(input_shape):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.GRU(units = 64, input_shape = input_shape))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "histories = []\n",
    "label_smoothings = [0, 0.05, 0.1]\n",
    "\n",
    "for ls in label_smoothings:\n",
    "    model = create_cnn_model((training_samples.shape[1], training_samples.shape[2]))\n",
    "\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=ls), metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    print(\"[INFO] fitting model...\")\n",
    "    history = model.fit(train_gen, epochs=100, validation_data=val_gen, callbacks=[early_stopping])\n",
    "\n",
    "    \n",
    "\n",
    "    histories.append(history)\n",
    "\n",
    "    del model\n",
    "\n",
    "lowest_loss = float('inf')\n",
    "lowest_loss_index = -1\n",
    "\n",
    "for i, history in enumerate(histories):\n",
    "    val_loss = history.history['val_loss'][-6] # we're using -6 since patience of early stopping is 5\n",
    "    if val_loss < lowest_loss:\n",
    "        lowest_loss = val_loss\n",
    "        lowest_loss_index = i\n",
    "\n",
    "print(f\"The label smoothing value with the lowest validation loss is {label_smoothings[lowest_loss_index]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
